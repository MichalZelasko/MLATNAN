{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4421fa0a-d4eb-474c-98fa-ad786c965e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f72f1863-9258-4e6e-823d-86e3211e74f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_file = 'Data/participants.tsv'\n",
    "data_directory = 'cc_matrices/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3146e856-ef30-4bb0-b500-0bd9c296d741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_matrix_from_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.readlines()\n",
    "        matrix = []\n",
    "        for line in content:\n",
    "            values = line.rstrip().split(',')\n",
    "            row = []\n",
    "            for val in values:\n",
    "                if val.strip():\n",
    "                    try:\n",
    "                        row.append(float(val))\n",
    "                    except ValueError:\n",
    "                        print(f\"Warning: Non-numeric value '{val}' found. Skipping.\")\n",
    "            if row:\n",
    "                matrix.append(row)\n",
    "    return np.array(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab9cb7a4-6d1f-4c52-b325-ab5496a4e66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Labels: ['CONTROL', 'ADHD', 'BIPOLAR', 'SCHZ']\n",
      "Labels:\n",
      " {10159: 0, 10171: 0, 10189: 0, 10193: 0, 10206: 0, 10217: 0, 10225: 0, 10227: 0, 10228: 0, 10235: 0, 10249: 0, 10269: 0, 10271: 0, 10273: 0, 10274: 0, 10280: 0, 10290: 0, 10292: 0, 10299: 0, 10304: 0, 10316: 0, 10321: 0, 10325: 0, 10329: 0, 10339: 0, 10340: 0, 10345: 0, 10347: 0, 10356: 0, 10361: 0, 10365: 0, 10376: 0, 10377: 0, 10388: 0, 10428: 0, 10429: 0, 10438: 0, 10440: 0, 10448: 0, 10455: 0, 10460: 0, 10471: 0, 10478: 0, 10487: 0, 10492: 0, 10501: 0, 10506: 0, 10517: 0, 10523: 0, 10524: 0, 10525: 0, 10527: 0, 10530: 0, 10557: 0, 10565: 0, 10570: 0, 10575: 0, 10624: 0, 10629: 0, 10631: 0, 10638: 0, 10668: 0, 10672: 0, 10674: 0, 10678: 0, 10680: 0, 10686: 0, 10692: 0, 10696: 0, 10697: 0, 10704: 0, 10707: 0, 10708: 0, 10719: 0, 10724: 0, 10746: 0, 10762: 0, 10779: 0, 10785: 0, 10788: 0, 10844: 0, 10855: 0, 10871: 0, 10877: 0, 10882: 0, 10891: 0, 10893: 0, 10912: 0, 10934: 0, 10940: 0, 10948: 0, 10949: 0, 10958: 0, 10963: 0, 10968: 0, 10971: 0, 10975: 0, 10977: 0, 10987: 0, 10998: 0, 11019: 0, 11030: 0, 11044: 0, 11050: 0, 11052: 0, 11059: 0, 11061: 0, 11062: 0, 11066: 0, 11067: 0, 11068: 0, 11077: 0, 11082: 0, 11088: 0, 11090: 0, 11097: 0, 11098: 0, 11104: 0, 11105: 0, 11106: 0, 11108: 0, 11112: 0, 11121: 0, 11122: 0, 11128: 0, 11131: 0, 11142: 0, 11143: 0, 11149: 0, 11156: 0, 50004: 3, 50005: 3, 50006: 3, 50007: 3, 50008: 3, 50010: 3, 50013: 3, 50014: 3, 50015: 3, 50016: 3, 50020: 3, 50021: 3, 50022: 3, 50023: 3, 50025: 3, 50027: 3, 50029: 3, 50032: 3, 50033: 3, 50034: 3, 50035: 3, 50036: 3, 50038: 3, 50043: 3, 50047: 3, 50048: 3, 50049: 3, 50050: 3, 50051: 3, 50052: 3, 50053: 3, 50054: 3, 50055: 3, 50056: 3, 50058: 3, 50059: 3, 50060: 3, 50061: 3, 50064: 3, 50066: 3, 50067: 3, 50069: 3, 50073: 3, 50075: 3, 50076: 3, 50077: 3, 50080: 3, 50081: 3, 50083: 3, 50085: 3, 60001: 2, 60005: 2, 60006: 2, 60008: 2, 60010: 2, 60011: 2, 60012: 2, 60014: 2, 60015: 2, 60016: 2, 60017: 2, 60020: 2, 60021: 2, 60022: 2, 60028: 2, 60030: 2, 60033: 2, 60036: 2, 60037: 2, 60038: 2, 60042: 2, 60043: 2, 60045: 2, 60046: 2, 60048: 2, 60049: 2, 60051: 2, 60052: 2, 60053: 2, 60055: 2, 60056: 2, 60057: 2, 60060: 2, 60062: 2, 60065: 2, 60066: 2, 60068: 2, 60070: 2, 60072: 2, 60073: 2, 60074: 2, 60076: 2, 60077: 2, 60078: 2, 60079: 2, 60080: 2, 60084: 2, 60087: 2, 60089: 2, 70001: 1, 70002: 1, 70004: 1, 70007: 1, 70010: 1, 70015: 1, 70017: 1, 70020: 1, 70021: 1, 70022: 1, 70026: 1, 70029: 1, 70033: 1, 70034: 1, 70035: 1, 70036: 1, 70037: 1, 70040: 1, 70046: 1, 70048: 1, 70049: 1, 70051: 1, 70052: 1, 70055: 1, 70057: 1, 70058: 1, 70060: 1, 70061: 1, 70065: 1, 70068: 1, 70069: 1, 70070: 1, 70072: 1, 70073: 1, 70074: 1, 70075: 1, 70076: 1, 70077: 1, 70079: 1, 70080: 1, 70081: 1, 70083: 1, 70086: 1}\n"
     ]
    }
   ],
   "source": [
    "participant_data = pd.read_csv(labels_file, sep='\\t')\n",
    "diagnosis_data = participant_data[['participant_id', 'diagnosis']]\n",
    "unique_labels = ['CONTROL', 'ADHD', 'BIPOLAR', 'SCHZ']\n",
    "\n",
    "labels_dict = dict(zip(diagnosis_data['participant_id'], diagnosis_data['diagnosis']))\n",
    "labels_dict = {int(key.replace('sub-', '')): value for key, value in labels_dict.items()}\n",
    "label_to_number = {label: i for i, label in enumerate(unique_labels)}\n",
    "numerical_labels_dict = {participant_id: label_to_number[label] for participant_id, label in labels_dict.items()}\n",
    "\n",
    "print(\"Unique Labels:\", unique_labels)\n",
    "print(\"Labels:\\n\", numerical_labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c74489e0-8f74-47dd-a178-423cf8d5d99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole dataset\n",
      "Counter({'CONTROL': 130, 'SCHZ': 50, 'BIPOLAR': 49, 'ADHD': 43})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "occurrences = Counter(labels_dict.values())\n",
    "print(\"Whole dataset\")\n",
    "print(occurrences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48c49cc9-6516-4f62-93a7-cfa8022d0c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    data = []\n",
    "    target = []\n",
    "    for filename in os.listdir(data_directory):\n",
    "        if filename.endswith('.txt'):\n",
    "            file_id = int(filename.split('-')[-1].split('.')[0])\n",
    "            if int(file_id) in labels_dict:\n",
    "                file_path = os.path.join(data_directory, filename)\n",
    "                matrix = read_matrix_from_file(file_path)\n",
    "                data.append(matrix)\n",
    "                label = labels_dict[file_id]\n",
    "                if label == \"CONTROL\":\n",
    "                    target.append(0)\n",
    "                else:\n",
    "                    target.append(1)\n",
    "            else:\n",
    "                raise Exception(f'{file_id} not in labels_dict')\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df99b256-c4f1-4391-bd94-fd01da992aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebd85e34-805e-479b-ab89-3f8385259f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current dataset\n",
      "Deleted file: size:112, idx:46, label:0\n",
      "Deleted file: size:113, idx:49, label:0\n",
      "Deleted file: size:112, idx:59, label:1\n",
      "Count of 0: 29\n",
      "Count of 1: 43\n"
     ]
    }
   ],
   "source": [
    "print(\"Current dataset\")\n",
    "for idx, d in enumerate(data):\n",
    "    if len(d) != 117:\n",
    "        print(f'Deleted file: size:{len(d)}, idx:{idx}, label:{target[idx]}')\n",
    "        del data[idx]\n",
    "        del target[idx]\n",
    "\n",
    "unique_values = set(target)\n",
    "for val in unique_values:\n",
    "    count = target.count(val)\n",
    "    print(f\"Count of {val}: {count}\")\n",
    "count_1 = target.count(0)\n",
    "count_2 = target.count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c0ea1a1-304d-4b75-b86c-2d1e508b5ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8167e2e3-ca3d-4642-b546-7a73e52445a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228ae67b-376c-42c0-a346-9fb56033d9ce",
   "metadata": {},
   "source": [
    "### Example notebook for GCN from PyTorch Geometric: https://colab.research.google.com/drive/1I8a0DfQ3fI7Njc62__mVXUlcAleUclnb?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dc6918-9547-4d09-88c0-35a22dff6038",
   "metadata": {},
   "source": [
    "### Prepare PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b14e17f1-ba85-4515-ac9a-50e2cb09778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.utils import dense_to_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "741895fa-3004-4dfb-b9da-913391c1756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_list(graphs, labels):\n",
    "    data_list = []\n",
    "    for graph, label in zip(graphs, labels):\n",
    "        # features\n",
    "        x = torch.tensor(graph).float()\n",
    "        # label\n",
    "        y = torch.tensor(label).long()\n",
    "        # adjacency matrix to list of edges\n",
    "        edge_index, edge_attr = dense_to_sparse(x)\n",
    "        data_list.append(Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y))\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0457bd87-8296-4eca-a4db-24d4518ed5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = create_data_list(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0419493c-a7bf-46b1-bd7b-dd58423a1b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "Data(x=[117, 117], edge_index=[2, 281], edge_attr=[281], y=1)\n"
     ]
    }
   ],
   "source": [
    "print(len(data_list))\n",
    "print(data_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc6961c5-e941-4881-a320-a513f22e41f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 58\n",
      "Number of test graphs: 14\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(data_list)\n",
    "\n",
    "train_dataset = data_list[:58]\n",
    "test_dataset = data_list[58:]\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6785a964-9f82-4b8e-9698-a135a41a0c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7050d6f7-6558-4a30-99ab-1f7b57bbc3f3",
   "metadata": {},
   "source": [
    "### Prepare GCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ac00046-4438-434c-9ee1-3c87920da2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(117, 64)\n",
      "  (conv3): GCNConv(64, 64)\n",
      "  (lin): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(117, hidden_channels)\n",
    "        # self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, 2)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        # x = self.conv2(x, edge_index)\n",
    "        # x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=64)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751f448c-f736-4a35-8cc9-1ebbeb7880b1",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e7667b7-6468-471d-8ded-f9a374d94767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 0.5862, Test Acc: 0.6429\n",
      "Epoch: 002, Train Acc: 0.5862, Test Acc: 0.6429\n",
      "Epoch: 003, Train Acc: 0.6034, Test Acc: 0.6429\n",
      "Epoch: 004, Train Acc: 0.6034, Test Acc: 0.6429\n",
      "Epoch: 005, Train Acc: 0.6034, Test Acc: 0.6429\n",
      "Epoch: 006, Train Acc: 0.6034, Test Acc: 0.6429\n",
      "Epoch: 007, Train Acc: 0.6034, Test Acc: 0.6429\n",
      "Epoch: 008, Train Acc: 0.6034, Test Acc: 0.6429\n",
      "Epoch: 009, Train Acc: 0.6897, Test Acc: 0.6429\n",
      "Epoch: 010, Train Acc: 0.6897, Test Acc: 0.6429\n",
      "Epoch: 011, Train Acc: 0.7069, Test Acc: 0.6429\n",
      "Epoch: 012, Train Acc: 0.7069, Test Acc: 0.6429\n",
      "Epoch: 013, Train Acc: 0.7241, Test Acc: 0.6429\n",
      "Epoch: 014, Train Acc: 0.7414, Test Acc: 0.6429\n",
      "Epoch: 015, Train Acc: 0.8276, Test Acc: 0.6429\n",
      "Epoch: 016, Train Acc: 0.8621, Test Acc: 0.7857\n",
      "Epoch: 017, Train Acc: 0.8103, Test Acc: 0.6429\n",
      "Epoch: 018, Train Acc: 0.9310, Test Acc: 0.7857\n",
      "Epoch: 019, Train Acc: 0.8966, Test Acc: 0.7857\n",
      "Epoch: 020, Train Acc: 0.8448, Test Acc: 0.7143\n",
      "Epoch: 021, Train Acc: 0.8966, Test Acc: 0.7857\n",
      "Epoch: 022, Train Acc: 0.9310, Test Acc: 0.7857\n",
      "Epoch: 023, Train Acc: 0.8793, Test Acc: 0.7143\n",
      "Epoch: 024, Train Acc: 0.8966, Test Acc: 0.7143\n",
      "Epoch: 025, Train Acc: 0.9483, Test Acc: 0.7857\n",
      "Epoch: 026, Train Acc: 0.8966, Test Acc: 0.7857\n",
      "Epoch: 027, Train Acc: 0.9483, Test Acc: 0.7857\n",
      "Epoch: 028, Train Acc: 0.9655, Test Acc: 0.7143\n",
      "Epoch: 029, Train Acc: 0.9655, Test Acc: 0.7857\n",
      "Epoch: 030, Train Acc: 0.9655, Test Acc: 0.7143\n",
      "Epoch: 031, Train Acc: 1.0000, Test Acc: 0.7143\n",
      "Epoch: 032, Train Acc: 1.0000, Test Acc: 0.7143\n",
      "Epoch: 033, Train Acc: 0.9655, Test Acc: 0.7857\n",
      "Epoch: 034, Train Acc: 0.9828, Test Acc: 0.7143\n",
      "Epoch: 035, Train Acc: 1.0000, Test Acc: 0.7143\n",
      "Epoch: 036, Train Acc: 1.0000, Test Acc: 0.7143\n",
      "Epoch: 037, Train Acc: 0.9828, Test Acc: 0.7143\n",
      "Epoch: 038, Train Acc: 1.0000, Test Acc: 0.7143\n",
      "Epoch: 039, Train Acc: 1.0000, Test Acc: 0.7143\n",
      "Epoch: 040, Train Acc: 1.0000, Test Acc: 0.7143\n",
      "Epoch: 041, Train Acc: 1.0000, Test Acc: 0.7143\n",
      "Epoch: 042, Train Acc: 0.9828, Test Acc: 0.7143\n",
      "Epoch: 043, Train Acc: 1.0000, Test Acc: 0.6429\n",
      "Epoch: 044, Train Acc: 1.0000, Test Acc: 0.7143\n",
      "Epoch: 045, Train Acc: 1.0000, Test Acc: 0.7143\n",
      "Epoch: 046, Train Acc: 1.0000, Test Acc: 0.7143\n",
      "Epoch: 047, Train Acc: 1.0000, Test Acc: 0.7143\n",
      "Epoch: 048, Train Acc: 1.0000, Test Acc: 0.6429\n",
      "Epoch: 049, Train Acc: 1.0000, Test Acc: 0.6429\n"
     ]
    }
   ],
   "source": [
    "model = GCN(hidden_channels=64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "         out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "         loss = criterion(out, data.y)  # Compute the loss.\n",
    "         loss.backward()  # Derive gradients.\n",
    "         optimizer.step()  # Update parameters based on gradients.\n",
    "         optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "def test(loader):\n",
    "     model.eval()\n",
    "\n",
    "     correct = 0\n",
    "     for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "         out = model(data.x, data.edge_index, data.batch)  \n",
    "         pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "         correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "     return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "for epoch in range(1, 50):\n",
    "    train()\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
